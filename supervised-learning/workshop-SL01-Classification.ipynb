{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop SL01: Classification\n",
    "\n",
    "## Agenda\n",
    "- Introduction to training and testing data distribution\n",
    "- Common classification models\n",
    "\n",
    "## Previously on the last 2 workshops\n",
    "From the last 2 workshops we have covered the pre-processing of data before model training: \n",
    "- Read data into dataframes\n",
    "- Join multiple dataframes\n",
    "- Encode string data into float/int\n",
    "- Feature selection/engineering \n",
    "\n",
    "## Exercise\n",
    "- find the best model and tune it for better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping the data\n",
    "These are from last 2 workshops straight, to get the dataframe to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# read csv file into a dataframe\n",
    "df_id_train = pd.read_csv(\"train_identity.csv\")\n",
    "df_tran_train = pd.read_csv(\"train_transaction.csv\")\n",
    "df_id_test = pd.read_csv(\"test_identity.csv\")\n",
    "df_tran_test = pd.read_csv(\"test_transaction.csv\")\n",
    "\n",
    "# joining table\n",
    "df_train = pd.merge(df_tran_train,df_id_train, on='TransactionID' ,how='left')\n",
    "\n",
    "# target dataframe \n",
    "Y_train = df_train['isFraud']\n",
    "Y_train = pd.DataFrame(Y_train)\n",
    "\n",
    "# dropping the irrelevant data for training\n",
    "list = ['isFraud','TransactionID','DeviceInfo']\n",
    "X_train = df_train.drop(list, axis=1)\n",
    "\n",
    "# encoding strings\n",
    "obj_df = X_train.select_dtypes(include=['object']).copy()\n",
    "int_df = X_train.select_dtypes(include=['int64']).copy()\n",
    "float_df = X_train.select_dtypes(include=['float64']).copy()\n",
    "\n",
    "for column in obj_df.head(0):\n",
    "    obj_df[column] = obj_df[column].astype('category')\n",
    "    obj_df[column] = obj_df[column].cat.codes\n",
    "\n",
    "X_train = pd.concat([obj_df,int_df,float_df],axis=1, sort=False) \n",
    "\n",
    "# filling na\n",
    "X_train.fillna(value=-1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can just download the dataframe as csv for future use. We only need to download it once, so in the future we just need to read these csv into dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloadig dataframe as csv\n",
    "X_train.to_csv (r'X_train.csv', index = None, header=True)\n",
    "Y_train.to_csv (r'Y_train.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv')\n",
    "Y_train = pd.read_csv('Y_train.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing/Training Set Distribution\n",
    "\n",
    "For model selection purpose we need to distribute the data into training and testing set, and compute model error on both sets, i.e. train error and test error. If we select model based on train error solely, we will have over-fitting problem because the model will just perform really well on training data but not on testing data. Test error is a better tool to judge whether the model will perform on new data. Perhaps this graph will explain better.\n",
    "\n",
    "<img src=\"train-test-error.png\">\n",
    "\n",
    "Source: [In-depth introduction to machine learning in 15 hours of expert videos](https://www.r-bloggers.com/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting test/train data into 80:20\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_size = int(0.8*X_train.shape[0])\n",
    "test_size = X_train.shape[0]-train_size\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_train, Y_train, train_size=train_size, test_size=test_size, random_state=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "#### 1) KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.966557  0.996736  0.981414    113954\n",
      "           1   0.375839  0.053924  0.094316      4154\n",
      "\n",
      "   micro avg   0.963576  0.963576  0.963576    118108\n",
      "   macro avg   0.671198  0.525330  0.537865    118108\n",
      "weighted avg   0.945780  0.963576  0.950214    118108\n",
      "\n",
      "[[113582    372]\n",
      " [  3930    224]]\n",
      "0.9635757103667829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import neighbors\n",
    "# training knn model\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "# Predict on new data\n",
    "Y_knn = knn.predict(X_test)\n",
    "# accuracy \n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "print (classification_report(Y_test, Y_knn,digits = 6))\n",
    "print (confusion_matrix(Y_test, Y_knn))\n",
    "print (accuracy_score(Y_test, Y_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is very bad because the model is very bad at detecting fraud transactions. Perhaps there is a way to put more penalty on false positve? This is an exercie to find out how!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Gaussian Processes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-ds",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
